#!/usr/bin/env python
#
# A MRJob definition for TileBrute. This is how we'll normalize
# launching the job locally in pseudo-distributed mode and on EMR.
#
# Before running the job, you'll need to build the java component if
# you haven't already.
#   $ mvn clean package
#
# To use with HadoopJobRunner:
#   $ HADOOP_HOME=/path/to/hadoop/install \
#     tilebrute -r hadoop \
#     --no-output -o out \ # <- these are important because otherwise
#                          #    MRJob will attempt to print your pngs
#                          #    to stdout o.O
#     /path/to/input.csv
#
# To use with EMRJobRunner:
#   $ AWS_ACCESS_KEY_ID=<aws-access-key> \
#     AWS_SECRET_ACCESS_KEY=<aws-secret-key> \
#     tilebrute \
#     -r emr \
#     --no-output \
#     --output-dir s3://path/to/output/tiles/
#     s3://path/to/input
#

from mrjob.job import MRJob
from mrjob.util import bash_wrap

class TileBrute(MRJob):

    # use this in combination with prepare_shapefiles
#    HADOOP_INPUT_FORMAT = 'org.apache.hadoop.mapred.lib.NLineInputFormat'

    # for generating Google TileID structure, ie, {z}/{x}/{y}.png
    HADOOP_OUTPUT_FORMAT = 'tilebrute.hadoop.mapred.MapTileOutputFormat'

    def mapper_cmd(self):
        return bash_wrap('$PYTHON -m tilebrute.sample_shapes')

    def reducer_cmd(self):
        return bash_wrap('$PYTHON -m tilebrute.draw_tiles')

if __name__ == '__main__':
    TileBrute.run()
